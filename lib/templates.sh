#!/bin/bash

#############################################
# Template Functions (deploy.sh, ssl.sh)
#############################################

# Create deployment script
create_deploy_script() {
    local username=$1
    local repository=$2
    local branch=$3
    local home_dir="/home/$username"
    local deploy_script="$home_dir/deploy.sh"
    
    cat > "$deploy_script" <<'DEPLOYEOF'
#!/bin/bash

#############################################
# Deployment Script
# Auto-generated by Cipi
#############################################

set -e

REPO_DIR="$HOME/wwwroot"
LOG_FILE="$HOME/logs/deploy.log"

echo "─────────────────────────────────────"
echo "Deployment started at $(date)"
echo "─────────────────────────────────────"

# Navigate to project directory
cd "$REPO_DIR"

# Git pull
echo "→ Pulling latest changes from Git..."
git pull origin BRANCH_PLACEHOLDER

# Check if Laravel project
if [ -f "artisan" ]; then
    echo "→ Laravel project detected"
    
    # Composer install
    echo "→ Installing Composer dependencies..."
    composer install --no-interaction --prefer-dist --optimize-autoloader --no-dev
    
    # Run migrations
    echo "→ Running database migrations..."
    php artisan migrate --force
    
    # Clear cache
    echo "→ Clearing cache..."
    php artisan cache:clear
    php artisan config:clear
    php artisan view:clear
    php artisan route:clear
    
    # Optimize
    echo "→ Optimizing application..."
    php artisan config:cache
    php artisan route:cache
    php artisan view:cache
    
    # Run npm if needed
    if [ -f "package.json" ]; then
        echo "→ Installing NPM dependencies..."
        npm install
        
        if grep -q "build" package.json; then
            echo "→ Building assets..."
            npm run build
        fi
    fi
    
    # Restart queue workers
    echo "→ Restarting queue workers..."
    php artisan queue:restart
fi

# Set permissions
echo "→ Setting permissions..."
find "$REPO_DIR" -type d -exec chmod 750 {} \;
find "$REPO_DIR" -type f -exec chmod 640 {} \;

if [ -d "$REPO_DIR/storage" ]; then
    chmod -R 770 "$REPO_DIR/storage"
fi

if [ -d "$REPO_DIR/bootstrap/cache" ]; then
    chmod -R 770 "$REPO_DIR/bootstrap/cache"
fi

echo "─────────────────────────────────────"
echo "Deployment completed at $(date)"
echo "─────────────────────────────────────"
DEPLOYEOF
    
    # Replace branch placeholder
    sed -i "s/BRANCH_PLACEHOLDER/$branch/g" "$deploy_script"
    
    # Set ownership and permissions
    chown "$username:$username" "$deploy_script"
    chmod 755 "$deploy_script"
    
    # Create webhook documentation
    create_webhook_docs "$username"
}

# Create SSL script
create_ssl_script() {
    local username=$1
    local home_dir="/home/$username"
    local ssl_script="$home_dir/ssl.sh"
    
    cat > "$ssl_script" <<'SSLEOF'
#!/bin/bash

#############################################
# SSL Certificate Management Script
# Auto-generated by Cipi
#############################################

set -e

# Get domain from Cipi storage
DOMAIN=$(sudo jq -r "to_entries[] | select(.value.app == \"USERNAME_PLACEHOLDER\") | .key" /etc/cipi/domains.json | head -n 1)

if [ -z "$DOMAIN" ]; then
    echo "Error: No domain assigned to this virtual host"
    echo "Please assign a domain first using: sudo cipi domain create"
    exit 1
fi

# Get aliases
ALIASES=$(sudo jq -r ".[\"$DOMAIN\"].aliases[]?" /etc/cipi/domains.json 2>/dev/null | tr '\n' ' ')

# Build domain list for certbot
DOMAIN_LIST="-d $DOMAIN"
HAS_WILDCARD=false
for alias in $ALIASES; do
    DOMAIN_LIST="$DOMAIN_LIST -d $alias"
    if [[ "$alias" == *"*"* ]]; then
        HAS_WILDCARD=true
    fi
done

# Check if main domain is wildcard
if [[ "$DOMAIN" == *"*"* ]]; then
    HAS_WILDCARD=true
fi

echo "─────────────────────────────────────"
echo "SSL Certificate Management"
echo "─────────────────────────────────────"
echo "Domain: $DOMAIN"
echo "Aliases: ${ALIASES:-(none)}"
echo ""

# Email for Let's Encrypt
EMAIL="USERNAME_PLACEHOLDER@USERNAME_PLACEHOLDER.local"

# Check for wildcard domains
if [ "$HAS_WILDCARD" = true ]; then
    echo "⚠️  WILDCARD DOMAIN DETECTED"
    echo "─────────────────────────────────────"
    echo ""
    echo "Wildcard domains (*.example.com) require DNS validation."
    echo "HTTP/Nginx validation will NOT work."
    echo ""
    echo "You need to:"
    echo "  1. Install a DNS provider plugin for certbot"
    echo "  2. Configure API credentials for your DNS provider"
    echo ""
    echo "Common DNS providers:"
    echo "  • Cloudflare:     apt install python3-certbot-dns-cloudflare"
    echo "  • Route53:        apt install python3-certbot-dns-route53"
    echo "  • DigitalOcean:   apt install python3-certbot-dns-digitalocean"
    echo ""
    echo "Example with Cloudflare:"
    echo "  1. Create /root/.secrets/cloudflare.ini with:"
    echo "     dns_cloudflare_api_token = YOUR_API_TOKEN"
    echo "  2. chmod 600 /root/.secrets/cloudflare.ini"
    echo "  3. sudo certbot certonly --dns-cloudflare \\"
    echo "       --dns-cloudflare-credentials /root/.secrets/cloudflare.ini \\"
    echo "       $DOMAIN_LIST \\"
    echo "       --non-interactive --agree-tos --email $EMAIL"
    echo ""
    echo "More info: https://eff-certbot.readthedocs.io/en/stable/using.html#dns-plugins"
    echo ""
    exit 1
fi

# Check if certificate exists
if [ -d "/etc/letsencrypt/live/$DOMAIN" ]; then
    echo "Certificate exists. Checking if renewal is needed..."
    sudo certbot renew --cert-name "$DOMAIN" --nginx --non-interactive
else
    echo "Requesting new certificate..."
    sudo certbot certonly --nginx $DOMAIN_LIST --non-interactive --agree-tos --email "$EMAIL"
    
    if [ $? -eq 0 ]; then
        echo "Certificate obtained successfully!"
        echo "Updating Nginx configuration..."
        
        # Update domain SSL status in storage
        sudo jq ".[\"$DOMAIN\"].ssl = true" /etc/cipi/domains.json > /tmp/domains.json
        sudo mv /tmp/domains.json /etc/cipi/domains.json
        sudo chmod 600 /etc/cipi/domains.json
        
        # Trigger Nginx config update with SSL
        echo "Please run: sudo cipi domain create --domain=$DOMAIN --app=USERNAME_PLACEHOLDER --aliases=\"$ALIASES\""
        echo "Or wait for the automatic SSL cron job to update the configuration"
    else
        echo "Error: Failed to obtain certificate"
        exit 1
    fi
fi

echo "─────────────────────────────────────"
echo "SSL management completed!"
echo "─────────────────────────────────────"
SSLEOF
    
    # Replace username placeholder
    sed -i "s/USERNAME_PLACEHOLDER/$username/g" "$ssl_script"
    
    # Set ownership and permissions
    chown "$username:$username" "$ssl_script"
    chmod 755 "$ssl_script"
}

# Create webhook documentation
create_webhook_docs() {
    local username=$1
    local home_dir="/home/$username"
    local webhook_doc="$home_dir/WEBHOOK_SETUP.md"
    local server_ip=$(get_server_ip)
    
    cat > "$webhook_doc" <<'WEBHOOKEOF'
# Webhook Setup Guide

This guide explains how to set up automatic deployments using Git webhooks.

## GitHub Webhook Setup

1. Go to your repository on GitHub
2. Click on **Settings** → **Webhooks** → **Add webhook**
3. Configure the webhook:

   **Payload URL:** 
   ```
   http://SERVER_IP_PLACEHOLDER/webhook/USERNAME_PLACEHOLDER
   ```
   
   **Content type:** `application/json`
   
   **Secret:** (leave empty for now)
   
   **Events:** Select "Just the push event"
   
   **Active:** Check this box

4. Click **Add webhook**

## GitLab Webhook Setup

1. Go to your repository on GitLab
2. Click on **Settings** → **Webhooks**
3. Configure the webhook:

   **URL:**
   ```
   http://SERVER_IP_PLACEHOLDER/webhook/USERNAME_PLACEHOLDER
   ```
   
   **Secret Token:** (leave empty for now)
   
   **Trigger:** Check "Push events"
   
   **Enable SSL verification:** Uncheck (unless you have SSL configured)

4. Click **Add webhook**

## Webhook Endpoint Setup (Nginx)

To receive webhooks, you need to add a webhook endpoint to your Nginx configuration.

Create a webhook handler file at `~/wwwroot/public/webhook.php`:

```php
<?php

// Verify webhook (optional - add secret validation here)
$secret = 'your-secret-key'; // Change this!

// Get payload
$payload = file_get_contents('php://input');
$data = json_decode($payload, true);

// Log webhook
file_put_contents(__DIR__ . '/../logs/webhook.log', date('Y-m-d H:i:s') . " - Webhook received\n", FILE_APPEND);

// Trigger deployment
$output = shell_exec('cd .. && ./deploy.sh 2>&1');
file_put_contents(__DIR__ . '/../logs/webhook.log', $output . "\n", FILE_APPEND);

// Return success
http_response_code(200);
echo json_encode(['status' => 'success', 'message' => 'Deployment triggered']);
```

Then update your Nginx configuration to handle the webhook URL:

```nginx
location /webhook/USERNAME_PLACEHOLDER {
    alias /home/USERNAME_PLACEHOLDER/wwwroot/public;
    try_files /webhook.php =404;
    
    location ~ \.php$ {
        fastcgi_pass unix:/var/run/php/php8.4-fpm-USERNAME_PLACEHOLDER.sock;
        fastcgi_param SCRIPT_FILENAME $request_filename;
        include fastcgi_params;
    }
}
```

After adding the configuration, reload Nginx:
```bash
sudo systemctl reload nginx
```

## Manual Deployment

You can always deploy manually by running:

```bash
cd /home/USERNAME_PLACEHOLDER
./deploy.sh
```

## Testing

To test if your webhook is working:

1. Make a small change to your repository
2. Push to your Git provider
3. Check the webhook logs:
   ```bash
   tail -f ~/logs/webhook.log
   ```

## Security Notes

- **Always use HTTPS** in production with valid SSL certificates
- **Add webhook secret verification** in your webhook.php handler
- **Validate the webhook source** (GitHub/GitLab IP ranges)
- **Limit webhook access** using firewall rules if needed

## Troubleshooting

If webhooks are not working:

1. Check Nginx error logs: `tail -f ~/logs/error.log`
2. Check webhook logs: `tail -f ~/logs/webhook.log`
3. Verify the webhook URL is accessible from the internet
4. Check file permissions: `ls -la ~/wwwroot/public/webhook.php`
5. Test manually: `curl http://SERVER_IP_PLACEHOLDER/webhook/USERNAME_PLACEHOLDER`
WEBHOOKEOF
    
    # Replace placeholders
    sed -i "s/SERVER_IP_PLACEHOLDER/$server_ip/g" "$webhook_doc"
    sed -i "s/USERNAME_PLACEHOLDER/$username/g" "$webhook_doc"
    
    # Set ownership
    chown "$username:$username" "$webhook_doc"
    chmod 644 "$webhook_doc"
}

# Create backup script
create_backup_script() {
    local username=$1
    local home_dir="/home/$username"
    local backup_script="$home_dir/backup.sh"
    
    cat > "$backup_script" <<'BACKUPEOF'
#!/bin/bash

#############################################
# Backup Script for Laravel Application
# Auto-generated by Cipi
#############################################

set -e

# ============================================
# CONFIGURATION - EDIT THESE VALUES
# ============================================

# S3 Configuration
S3_BUCKET="your-bucket-name"                    # Your S3 bucket name
S3_REGION="us-east-1"                           # AWS region (e.g., us-east-1, eu-west-1)
AWS_ACCESS_KEY_ID="YOUR_ACCESS_KEY"             # Your AWS Access Key ID
AWS_SECRET_ACCESS_KEY="YOUR_SECRET_KEY"         # Your AWS Secret Access Key

# Backup Configuration
BACKUP_RETENTION_DAYS=30                        # Keep backups for N days
BACKUP_NAME="USERNAME_PLACEHOLDER"              # Backup prefix name

# ============================================
# DO NOT EDIT BELOW THIS LINE
# ============================================

# Paths
APP_DIR="$HOME/wwwroot"
STORAGE_DIR="$APP_DIR/storage"
BACKUP_DIR="$HOME/backups"
LOG_FILE="$HOME/logs/backup.log"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="${BACKUP_NAME}_${TIMESTAMP}.tar.gz"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m'

# Logging function
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

error() {
    echo -e "${RED}[ERROR] $1${NC}" | tee -a "$LOG_FILE"
    exit 1
}

success() {
    echo -e "${GREEN}[SUCCESS] $1${NC}" | tee -a "$LOG_FILE"
}

warning() {
    echo -e "${YELLOW}[WARNING] $1${NC}" | tee -a "$LOG_FILE"
}

# Check if S3 is configured
if [ "$S3_BUCKET" = "your-bucket-name" ]; then
    error "Please configure S3 settings in this script before running backup!"
fi

# Check if AWS CLI is installed
if ! command -v aws &> /dev/null; then
    error "AWS CLI is not installed. This should not happen with Cipi installation."
fi

# Export AWS credentials
export AWS_ACCESS_KEY_ID
export AWS_SECRET_ACCESS_KEY
export AWS_DEFAULT_REGION="$S3_REGION"

log "============================================"
log "Starting backup process"
log "============================================"

# Create backup directory
mkdir -p "$BACKUP_DIR"
mkdir -p "$(dirname "$LOG_FILE")"

# Create temporary backup directory
TEMP_BACKUP="$BACKUP_DIR/temp_${TIMESTAMP}"
mkdir -p "$TEMP_BACKUP"

log "Temporary backup location: $TEMP_BACKUP"

# ============================================
# BACKUP LARAVEL STORAGE
# ============================================

log "Backing up Laravel storage directory..."

if [ -d "$STORAGE_DIR" ]; then
    cp -r "$STORAGE_DIR" "$TEMP_BACKUP/storage"
    success "Storage directory backed up"
else
    warning "Storage directory not found, skipping..."
fi

# ============================================
# BACKUP DATABASE
# ============================================

log "Reading database configuration from .env..."

if [ ! -f "$APP_DIR/.env" ]; then
    warning ".env file not found, skipping database backup"
else
    # Read database configuration
    DB_CONNECTION=$(grep DB_CONNECTION "$APP_DIR/.env" | cut -d '=' -f2 | tr -d '"' | tr -d "'")
    DB_HOST=$(grep DB_HOST "$APP_DIR/.env" | cut -d '=' -f2 | tr -d '"' | tr -d "'")
    DB_PORT=$(grep DB_PORT "$APP_DIR/.env" | cut -d '=' -f2 | tr -d '"' | tr -d "'")
    DB_DATABASE=$(grep DB_DATABASE "$APP_DIR/.env" | cut -d '=' -f2 | tr -d '"' | tr -d "'")
    DB_USERNAME=$(grep DB_USERNAME "$APP_DIR/.env" | cut -d '=' -f2 | tr -d '"' | tr -d "'")
    DB_PASSWORD=$(grep DB_PASSWORD "$APP_DIR/.env" | cut -d '=' -f2 | tr -d '"' | tr -d "'")

    log "Database type: ${DB_CONNECTION:-not set}"

    case "$DB_CONNECTION" in
        mysql)
            log "Backing up MySQL database: $DB_DATABASE"
            
            if command -v mysqldump &> /dev/null; then
                mysqldump -h "${DB_HOST:-127.0.0.1}" \
                          -P "${DB_PORT:-3306}" \
                          -u "$DB_USERNAME" \
                          -p"$DB_PASSWORD" \
                          "$DB_DATABASE" > "$TEMP_BACKUP/database.sql"
                
                if [ $? -eq 0 ]; then
                    success "MySQL database backed up"
                else
                    error "Failed to backup MySQL database"
                fi
            else
                error "mysqldump not found"
            fi
            ;;
            
        sqlite)
            log "Backing up SQLite database: $DB_DATABASE"
            
            if [ -f "$APP_DIR/database/$DB_DATABASE" ]; then
                cp "$APP_DIR/database/$DB_DATABASE" "$TEMP_BACKUP/database.sqlite"
                success "SQLite database backed up"
            elif [ -f "$APP_DIR/$DB_DATABASE" ]; then
                cp "$APP_DIR/$DB_DATABASE" "$TEMP_BACKUP/database.sqlite"
                success "SQLite database backed up"
            else
                warning "SQLite database file not found"
            fi
            ;;
            
        pgsql)
            log "Backing up PostgreSQL database: $DB_DATABASE"
            
            if command -v pg_dump &> /dev/null; then
                PGPASSWORD="$DB_PASSWORD" pg_dump -h "${DB_HOST:-127.0.0.1}" \
                                                   -p "${DB_PORT:-5432}" \
                                                   -U "$DB_USERNAME" \
                                                   "$DB_DATABASE" > "$TEMP_BACKUP/database.sql"
                
                if [ $? -eq 0 ]; then
                    success "PostgreSQL database backed up"
                else
                    error "Failed to backup PostgreSQL database"
                fi
            else
                error "pg_dump not found"
            fi
            ;;
            
        *)
            warning "Unknown or unsupported database type: $DB_CONNECTION"
            ;;
    esac
fi

# ============================================
# CREATE BACKUP ARCHIVE
# ============================================

log "Creating compressed archive..."

cd "$BACKUP_DIR"
tar -czf "$BACKUP_FILE" -C "$TEMP_BACKUP" .

if [ $? -eq 0 ]; then
    success "Archive created: $BACKUP_FILE"
    BACKUP_SIZE=$(du -h "$BACKUP_DIR/$BACKUP_FILE" | cut -f1)
    log "Backup size: $BACKUP_SIZE"
else
    error "Failed to create archive"
fi

# Cleanup temporary directory
rm -rf "$TEMP_BACKUP"

# ============================================
# UPLOAD TO S3
# ============================================

log "Uploading backup to S3..."

aws s3 cp "$BACKUP_DIR/$BACKUP_FILE" "s3://$S3_BUCKET/backups/$BACKUP_NAME/" \
    --region "$S3_REGION" \
    --storage-class STANDARD_IA

if [ $? -eq 0 ]; then
    success "Backup uploaded to S3: s3://$S3_BUCKET/backups/$BACKUP_NAME/$BACKUP_FILE"
else
    error "Failed to upload backup to S3"
fi

# ============================================
# CLEANUP OLD LOCAL BACKUPS
# ============================================

log "Cleaning up old local backups (older than $BACKUP_RETENTION_DAYS days)..."

find "$BACKUP_DIR" -name "${BACKUP_NAME}_*.tar.gz" -mtime +$BACKUP_RETENTION_DAYS -delete

# ============================================
# CLEANUP OLD S3 BACKUPS
# ============================================

log "Cleaning up old S3 backups (older than $BACKUP_RETENTION_DAYS days)..."

# Get list of old backups from S3
OLD_DATE=$(date -d "$BACKUP_RETENTION_DAYS days ago" +%Y%m%d)

aws s3 ls "s3://$S3_BUCKET/backups/$BACKUP_NAME/" --region "$S3_REGION" | \
while read -r line; do
    FILE_DATE=$(echo "$line" | awk '{print $4}' | grep -oP '\d{8}' | head -1)
    FILE_NAME=$(echo "$line" | awk '{print $4}')
    
    if [ -n "$FILE_DATE" ] && [ "$FILE_DATE" -lt "$OLD_DATE" ]; then
        log "Deleting old backup from S3: $FILE_NAME"
        aws s3 rm "s3://$S3_BUCKET/backups/$BACKUP_NAME/$FILE_NAME" --region "$S3_REGION"
    fi
done

# ============================================
# BACKUP COMPLETE
# ============================================

log "============================================"
success "Backup completed successfully!"
log "Local backup: $BACKUP_DIR/$BACKUP_FILE"
log "S3 location: s3://$S3_BUCKET/backups/$BACKUP_NAME/$BACKUP_FILE"
log "============================================"

# Optional: Remove local backup after successful S3 upload
# Uncomment the line below if you want to keep only S3 backups
# rm -f "$BACKUP_DIR/$BACKUP_FILE"

exit 0
BACKUPEOF
    
    # Replace username placeholder
    sed -i "s/USERNAME_PLACEHOLDER/$username/g" "$backup_script"
    
    # Set ownership and permissions
    chown "$username:$username" "$backup_script"
    chmod 755 "$backup_script"
    
    # Create backups directory
    mkdir -p "$home_dir/backups"
    chown "$username:$username" "$home_dir/backups"
    chmod 755 "$home_dir/backups"
}


